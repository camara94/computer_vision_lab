{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ecommerce_computer_vision.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwi/BM/Qd3oHIVzgJPFmXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camara94/computer_vision_lab/blob/main/ecommerce_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TldvwxERMhvd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wq1zIfwTQvFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "id": "nVZRUiYTNQG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./drive/MyDrive/data_4"
      ],
      "metadata": {
        "id": "jK6hFjZ0ODeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = './drive/MyDrive/data_4'"
      ],
      "metadata": {
        "id": "5-beGnx5OStg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_classes = len(liste_dossier)\n",
        "# n_classes\n",
        "\n",
        "# classes = []\n",
        "\n",
        "# for c in liste_dossier:\n",
        "#     classes.append(' '.join(c.title().split('_')))\n",
        "\n",
        "# for classe in classes:\n",
        "#     with open(\"ecommerce_computer_vision/classes.txt\", \"a+\", encoding=\"UTF-8\") as fichier:\n",
        "#         fichier.write(classe + \"\\n\")"
      ],
      "metadata": {
        "id": "7wZpjGI-PJK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32 \n",
        "classes = []\n",
        "liste_dossier = os.listdir(base_dir+'/train')\n",
        "for c in liste_dossier:\n",
        "    classes.append(' '.join(c.title().split('_')))\n",
        "classes[:4]"
      ],
      "metadata": {
        "id": "UXRWFcHpPOfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our example directories and files\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "test_dir = os.path.join( base_dir, 'test')\n",
        "validation_dir = os.path.join( base_dir, 'val')\n",
        "\n",
        "\n",
        "\n",
        "# Ajouter nos paramètres d'augmentation de données à ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
        "                                   # data augmentation\n",
        "                                   rotation_range = 50,\n",
        "                                   width_shift_range = 0.3,\n",
        "                                   height_shift_range = 0.3,\n",
        "                                   shear_range = 0.3,\n",
        "                                   zoom_range = 0.3,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Notez que les données de validation ne doivent pas être augmentées !\n",
        "validation_datagen = ImageDataGenerator( rescale = 1.0/255 )\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255 )\n",
        "\n",
        "# Images d'entraînement de flux par lots de 20 à l'aide du générateur train_datagen\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 895,\n",
        "                                                    class_mode = 'categorical', \n",
        "                                                    target_size = (56, 56))  \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 111,\n",
        "                                                          class_mode  = 'categorical', \n",
        "                                                          target_size = (56, 56))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "test_generator =  test_datagen.flow_from_directory( test_dir,\n",
        "                                                          batch_size  = 115,\n",
        "                                                          class_mode  = 'categorical', \n",
        "                                                          target_size = (56, 56))"
      ],
      "metadata": {
        "id": "itoZ8TI8RbWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_generator)"
      ],
      "metadata": {
        "id": "29oe-nCZ2X7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims"
      ],
      "metadata": {
        "id": "ssAbk3FncTJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n",
        "Input size is 224 x 224.\n",
        "'''\n",
        "def feature_extractor(inputs):\n",
        "\n",
        "  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')(inputs)\n",
        "  return feature_extractor"
      ],
      "metadata": {
        "id": "AeCtCxUOfyWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Defines final dense layers and subsequent softmax layer for classification.\n",
        "'''\n",
        "def classifier(inputs):\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    # Ajoutez une couche entièrement connectée avec 1 024 unités cachées et l'activation ReLU\n",
        "    x = Dense(1024, activation=keras.layers.ReLU())(x)\n",
        "\n",
        "    # Ajouter un taux d'abandon de 0,2\n",
        "    x = Dropout(0.1)(x) \n",
        "\n",
        "    # Ajoutez une couche entièrement connectée avec 1 024 unités cachées et l'activation ReLU\n",
        "    x = Dense(512, activation=keras.layers.ReLU())(x)\n",
        "\n",
        "    # Ajouter un taux d'abandon de 0,2\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    # # Ajoutez une couche entièrement connectée avec 1 024 unités cachées et l'activation ReLU\n",
        "    x = Dense(256, activation=keras.layers.ReLU())(x)\n",
        "\n",
        "    # # Ajouter un taux d'abandon de 0,2\n",
        "    x = Dropout(0.1)(x) \n",
        "\n",
        "    x = tf.keras.layers.Dense(len(classes), activation=\"softmax\", name=\"classification\")(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ObKFznvyf8Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Since input image size is (56 x 56), first upsample the image by factor of (4x4) to transform it to (224 x 224)\n",
        "Connect the feature extraction and \"classifier\" layers to build the model.\n",
        "'''\n",
        "def final_model(inputs):\n",
        "\n",
        "    resize = tf.keras.layers.UpSampling2D(size=(4,4))(inputs)\n",
        "\n",
        "    resnet_feature_extractor = feature_extractor(resize)\n",
        "    classification_output = classifier(resnet_feature_extractor)\n",
        "\n",
        "    return classification_output"
      ],
      "metadata": {
        "id": "zKoCAc0ogOUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define the model and compile it. \n",
        "Use Stochastic Gradient Descent as the optimizer.\n",
        "Use Sparse Categorical CrossEntropy as the loss function.\n",
        "'''\n",
        "def define_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(56,56,3))\n",
        "  \n",
        "  classification_output = final_model(inputs) \n",
        "  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
        " \n",
        "  model.compile(optimizer='SGD', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "VVRqzW3FgaQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_compile_model()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hGDSupEFgieB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définissez une classe de rappel qui arrête l'entraînement une fois que la précision atteint 99.9 %\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.99):\n",
        "            print(\"\\nAtteint 98 % de précision, donc annulation de l'entraînement !\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "1tss4cVYg9Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = []\n",
        "training_labels = []\n",
        "training_label = []\n",
        "training_images.append( np.array(train_generator[0][0]) )\n",
        "training_label = [np.argmax(i) for i in train_generator[0][1]]\n",
        "training_labels.append( np.array(training_label).reshape(np.array(training_label).shape[0], 1) )"
      ],
      "metadata": {
        "id": "cLqoPjkonEr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_images = []\n",
        "validation_labels = []\n",
        "validation_label = []\n",
        "validation_images.append( np.array(validation_generator[0][0]) )\n",
        "validation_label = [np.argmax(i) for i in validation_generator[0][1]]\n",
        "validation_labels.append( np.array(validation_label).reshape(np.array(validation_label).shape[0], 1) )"
      ],
      "metadata": {
        "id": "39DFZeoI5nc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels = np.array(training_labels)\n",
        "training_images = np.array(training_images)\n",
        "\n",
        "validation_labels = np.array(validation_labels)\n",
        "validation_images = np.array(validation_images)\n",
        "    "
      ],
      "metadata": {
        "id": "SNOe2alovezy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training_images.ndim == 5:\n",
        "    training_images = training_images[0]\n",
        "training_images.shape"
      ],
      "metadata": {
        "id": "zhp4YTKA4KPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if validation_images.ndim == 5:\n",
        "    validation_images = validation_images[0]\n",
        "validation_images.shape"
      ],
      "metadata": {
        "id": "6gr6cA7e6bwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_label = np.array(training_images)\n",
        "# training_label = training_label.reshape(training_label.shape[0], 1)\n",
        "training_labels = training_labels[0]\n",
        "training_labels.shape "
      ],
      "metadata": {
        "id": "KVkM-vsA4vnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MlGxobjG6oyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation_labels = np.array(validation_labels)\n",
        "# validation_labels = training_label.reshape(validation_labels.shape[0], 1)\n",
        "validation_labels = validation_labels[0]\n",
        "validation_labels.shape"
      ],
      "metadata": {
        "id": "TsmYvAu46o0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims"
      ],
      "metadata": {
        "id": "CXhslg0CrIBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_X = preprocess_image_input(training_images)\n",
        "# valid_X = preprocess_image_input(validation_images)"
      ],
      "metadata": {
        "id": "szGDswkB5eFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this will take around 20 minutes to complete\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    training_images, \n",
        "    training_labels, \n",
        "    epochs=EPOCHS, \n",
        "    validation_data = (validation_images, validation_labels), \n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "DJjdKyH2gkyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_h-SGcrXnCo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "On6jZ6GdhBwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}